from src.data_loader import load_data, save_data
from src.data_cleaning import clean_data
from src.text_cleaning import clean_text
from src.sentiment_analysis import get_sentiment
from src.kpi_extraction import prepare_date_features, extract_kpi

# ğŸ”¹ Ã‰tape 1 : Chargement des donnÃ©es brutes
file_path = "Data/filtered_tweets_engie.csv"
data = load_data(file_path)

# ğŸ”¹ Ã‰tape 2 : Nettoyage des donnÃ©es
data = clean_data(data)

# ğŸ”¹ Ã‰tape 3 : Nettoyage du texte et analyse de sentiment
data['full_text'] = data['full_text'].apply(clean_text)
data['sentiment'] = data['full_text'].apply(get_sentiment)

# ğŸ”¹ Ã‰tape 4 : Extraction des KPI
data = prepare_date_features(data)
kpi_results = extract_kpi(data)

# ğŸ”¹ Ã‰tape 5 : Sauvegarde du fichier final
output_path = "CHALL-48H-IA/output/filtered_tweets_engie_final.csv"
save_data(data, output_path)

# ğŸ”¹ Ã‰tape 6 : Affichage des KPI
print(f"âœ… DonnÃ©es nettoyÃ©es et enregistrÃ©es dans : `{output_path}`")
print(f"ğŸ“Š Nombre total de tweets : {kpi_results['total_tweets']}")
print(f"ğŸ“… Tweets par jour :\n{kpi_results['tweets_per_day']}")
print(f"ğŸ“… Tweets par semaine :\n{kpi_results['tweets_per_week']}")
print(f"ğŸ“… Tweets par mois :\n{kpi_results['tweets_per_month']}")
print(f"ğŸ•’ RÃ©partition par heure :\n{kpi_results['tweets_per_hour']}")
print(f"ğŸ“… RÃ©partition par jour de la semaine :\n{kpi_results['tweets_per_day_of_week']}")
print(f"âš ï¸ Nombre de tweets critiques : {kpi_results['critical_tweets']}")
print(f"ğŸ˜° Score d'inconfort : {kpi_results['discomfort_score']}%")
